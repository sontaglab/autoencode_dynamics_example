{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ae_latentODE_twoPhase_pretrain_then_anneal_savefigs_combinedZoom_withRadius_FIXED.py\n",
        "# - Phase 1: AE pretrain on ||D(E(x)) - x||^2\n",
        "# - Phase 2..4: introduce conjugacy + latent RK4 losses (annealed)\n",
        "# - Encoder: deep MLP R^2->R (no atan2 prior)\n",
        "# - Decoder: unconstrained MLP R->R^2 (no projection)\n",
        "# - Latent ODE: 1D MLP, RK4 stepping\n",
        "# - Figures saved to ./results_latentODE/ with names matching LaTeX\n",
        "# - \"Zoom\" figure is the combined true + pulled-back with y-lims [-2.2, 2.2]\n",
        "# - Radius plot included; A'..H' radii printed to console\n",
        "# - FIX: no usage of numpy .astype on torch tensors\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# Central output directory\n",
        "# ----------------------------\n",
        "SAVE_DIR = \"./results_latentODE\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "def savefig(name):\n",
        "    plt.savefig(os.path.join(SAVE_DIR, name), dpi=200, bbox_inches='tight')\n",
        "\n",
        "# ----------------------------\n",
        "# Repro / device\n",
        "# ----------------------------\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "torch.set_default_dtype(torch.float32)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# ----------------------------\n",
        "# Data & dynamics\n",
        "# ----------------------------\n",
        "DT       = 0.04\n",
        "N_TRAJ   = 512\n",
        "STEPS    = 96\n",
        "\n",
        "def theta_dot(theta):\n",
        "    return np.sin(2.0*theta)\n",
        "\n",
        "def theta_to_xy(theta):\n",
        "    return np.stack([np.cos(theta), np.sin(theta)], axis=-1).astype(np.float32)\n",
        "\n",
        "def simulate_thetas(n_traj=N_TRAJ, steps=STEPS, dt=DT, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    theta0 = rng.uniform(0, 2*np.pi, size=n_traj)\n",
        "    thetas = np.zeros((n_traj, steps), dtype=np.float32)\n",
        "    thetas[:, 0] = theta0.astype(np.float32)\n",
        "    for t in range(1, steps):\n",
        "        th = thetas[:, t-1]\n",
        "        thetas[:, t] = (th + dt * theta_dot(th)).astype(np.float32)\n",
        "    return thetas\n",
        "\n",
        "thetas = simulate_thetas(seed=42)\n",
        "X = theta_to_xy(thetas)              # (N,T,2)\n",
        "X_flat = X.reshape(-1, 2)\n",
        "X_t   = X[:, :-1, :].reshape(-1, 2)\n",
        "X_tp1 = X[:,  1:, :].reshape(-1, 2)\n",
        "X_tensor = torch.from_numpy(X_flat).to(DEVICE)\n",
        "X_t      = torch.from_numpy(X_t).to(DEVICE)\n",
        "X_tp1    = torch.from_numpy(X_tp1).to(DEVICE)\n",
        "\n",
        "# ----------------------------\n",
        "# Labeled initial conditions (A..H)\n",
        "# ----------------------------\n",
        "ICS = {\n",
        "    \"A\": 0.0,\n",
        "    \"B\": np.pi/6,\n",
        "    \"C\": np.pi/5,\n",
        "    \"D\": np.pi/4,\n",
        "    \"E\": 3*np.pi/4,\n",
        "    \"F\": np.pi,\n",
        "    \"G\": 5*np.pi/4,\n",
        "    \"H\": 4*np.pi/3,\n",
        "}\n",
        "TAG_LIST = list(ICS.keys())\n",
        "COLOR_LIST = plt.rcParams['axes.prop_cycle'].by_key().get('color', None)\n",
        "if COLOR_LIST is None or len(COLOR_LIST) < len(TAG_LIST):\n",
        "    COLOR_LIST = ['C0','C1','C2','C3','C4','C5','C6','C7']\n",
        "TAG_TO_COLOR = {tag: COLOR_LIST[i % len(COLOR_LIST)] for i, tag in enumerate(TAG_LIST)}\n",
        "\n",
        "# ----------------------------\n",
        "# Models\n",
        "# ----------------------------\n",
        "class EncoderDeep(nn.Module):\n",
        "    def __init__(self, in_dim=2, hidden=128, depth=3, out_dim=1, act=nn.Tanh):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(in_dim, hidden), act()]\n",
        "        for _ in range(depth-1):\n",
        "            layers += [nn.Linear(hidden, hidden), act()]\n",
        "        layers += [nn.Linear(hidden, out_dim)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_dim=1, hidden=128, out_dim=2, act=nn.Tanh):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden), act(),\n",
        "            nn.Linear(hidden, hidden), act(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, phi): return self.net(phi)  # no projection\n",
        "\n",
        "class LatentODE(nn.Module):\n",
        "    def __init__(self, in_dim=1, hidden=64, out_dim=1, act=nn.Tanh):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden), act(),\n",
        "            nn.Linear(hidden, hidden), act(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, phi): return self.net(phi)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = EncoderDeep()\n",
        "        self.dec = Decoder()\n",
        "        self.h   = LatentODE()\n",
        "    def forward(self, x):\n",
        "        phi = self.enc(x)\n",
        "        xhat = self.dec(phi)\n",
        "        return xhat, phi\n",
        "\n",
        "model = Model().to(DEVICE)\n",
        "\n",
        "# ----------------------------\n",
        "# Loss utilities\n",
        "# ----------------------------\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "def rk4_step(z, h, dt):\n",
        "    k1 = h(z)\n",
        "    k2 = h(z + 0.5*dt*k1)\n",
        "    k3 = h(z + 0.5*dt*k2)\n",
        "    k4 = h(z + dt*k3)\n",
        "    return z + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
        "\n",
        "def true_field_xy_from_any_x(x):\n",
        "    x1, x2 = x[:,0], x[:,1]\n",
        "    theta = torch.atan2(x2, x1)\n",
        "    thdot = torch.sin(2.0*theta)\n",
        "    tx, ty = -torch.sin(theta), torch.cos(theta)\n",
        "    return torch.stack([thdot*tx, thdot*ty], dim=1)\n",
        "\n",
        "def conjugacy_loss(model, x_batch):\n",
        "    x_batch = x_batch.requires_grad_(True)\n",
        "    phi = model.enc(x_batch)\n",
        "    phi.requires_grad_(True)\n",
        "    x_dec = model.dec(phi)\n",
        "    h_phi = model.h(phi)\n",
        "    grads = []\n",
        "    for i in range(2):\n",
        "        g = torch.autograd.grad(x_dec[:, i].sum(), phi,\n",
        "                                retain_graph=True, create_graph=True)[0]\n",
        "        grads.append(g)\n",
        "    J = torch.cat(grads, dim=1)   # (B,2)\n",
        "    v_push = J * h_phi\n",
        "    f_true = true_field_xy_from_any_x(x_dec)\n",
        "    return ((v_push - f_true)**2).mean()\n",
        "\n",
        "# ----------------------------\n",
        "# Training schedules (two-phase / annealed)\n",
        "# ----------------------------\n",
        "SCHEDULE = [\n",
        "    (500, 15.0, 0.0, 0.0, 2e-3),   # AE pretrain\n",
        "    (250, 10.0, 0.5, 0.2, 1.5e-3),\n",
        "    (250,  7.0, 1.0, 0.5, 1.0e-3),\n",
        "    (250,  5.0, 2.0, 0.8, 1.0e-3),\n",
        "]\n",
        "BATCH = 4096\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "def train_with_schedule(model, schedule=SCHEDULE):\n",
        "    N_all  = X_tensor.shape[0]\n",
        "    N_pairs= X_t.shape[0]\n",
        "\n",
        "    for phase, (EPOCHS, W_REC, W_CONJ, W_LAT1, LR) in enumerate(schedule, 1):\n",
        "        opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "        print(f\"\\n=== Phase {phase} | epochs={EPOCHS} | W_REC={W_REC} \"\n",
        "              f\"W_CONJ={W_CONJ} W_LAT1={W_LAT1} | lr={LR} ===\")\n",
        "        for ep in range(EPOCHS):\n",
        "            # Reconstruction batch\n",
        "            idx = torch.randint(0, N_all, (BATCH,))\n",
        "            xb  = X_tensor[idx]\n",
        "            xhat, phi = model(xb)\n",
        "            L_rec = mse(xhat, xb)\n",
        "\n",
        "            # Conjugacy\n",
        "            L_conj = torch.tensor(0.0, device=DEVICE)\n",
        "            if W_CONJ > 0.0:\n",
        "                idxc = torch.randint(0, N_all, (BATCH,))\n",
        "                xc   = X_tensor[idxc]\n",
        "                L_conj = conjugacy_loss(model, xc)\n",
        "\n",
        "            # Latent one-step\n",
        "            L_lat1 = torch.tensor(0.0, device=DEVICE)\n",
        "            if W_LAT1 > 0.0:\n",
        "                idxp = torch.randint(0, N_pairs, (BATCH,))\n",
        "                xt, xtp1 = X_t[idxp], X_tp1[idxp]\n",
        "                phi_t = model.enc(xt)\n",
        "                phi_tp1_enc = model.enc(xtp1).detach()\n",
        "                phi_tp1_pred = rk4_step(phi_t, model.h, DT)\n",
        "                L_lat1 = mse(phi_tp1_pred, phi_tp1_enc)\n",
        "\n",
        "            loss = W_REC*L_rec + W_CONJ*L_conj + W_LAT1*L_lat1\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "\n",
        "            if (ep+1) % 100 == 0 or ep == 0:\n",
        "                print(f\"  ep {ep+1:4d} | rec {L_rec.item():.3e} \"\n",
        "                      f\"| conj {L_conj.item():.3e} | lat1 {L_lat1.item():.3e} \"\n",
        "                      f\"| total {loss.item():.3e}\")\n",
        "\n",
        "train_with_schedule(model, SCHEDULE)\n",
        "\n",
        "# ----------------------------\n",
        "# Plot helpers\n",
        "# ----------------------------\n",
        "def wrap_angle_numpy(a):\n",
        "    return ((a + np.pi) % (2*np.pi)) - np.pi\n",
        "\n",
        "def annotate_points_on_circle(ax, labels_to_theta):\n",
        "    for tag, th in labels_to_theta.items():\n",
        "        x, y = np.cos(th), np.sin(th)\n",
        "        ax.scatter([x], [y], s=50, color=TAG_TO_COLOR[tag])\n",
        "        ax.text(x+0.05, y+0.05, tag, fontsize=11, weight='bold',\n",
        "                color=TAG_TO_COLOR[tag])\n",
        "\n",
        "def quiver_circle_with_labels():\n",
        "    def f_on_circle_xy(theta):\n",
        "        thdot = np.sin(2.0*theta)\n",
        "        tx, ty = -np.sin(theta), np.cos(theta)\n",
        "        return np.stack([thdot*tx, thdot*ty], axis=-1)\n",
        "    theta_q = np.linspace(0, 2*np.pi, 36, endpoint=False)\n",
        "    circle = np.stack([np.cos(theta_q), np.sin(theta_q)], axis=-1)\n",
        "    vecs = f_on_circle_xy(theta_q)\n",
        "    vecs = vecs / np.maximum(1e-8, np.linalg.norm(vecs, axis=-1, keepdims=True))\n",
        "    plt.figure(figsize=(5.5,5.5))\n",
        "    td = np.linspace(0, 2*np.pi, 400)\n",
        "    plt.plot(np.cos(td), np.sin(td), color='0.7')\n",
        "    plt.quiver(circle[:,0], circle[:,1], vecs[:,0], vecs[:,1],\n",
        "               angles='xy', scale_units='xy', scale=12, width=0.005)\n",
        "    annotate_points_on_circle(plt.gca(), ICS)\n",
        "    plt.gca().set_aspect('equal', 'box')\n",
        "    plt.title(r\"Original flow on S$^1$: $\\dot{\\theta} = \\sin(2\\theta)$\")\n",
        "    plt.xlabel(\"x₁\"); plt.ylabel(\"x₂\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_flow_S1.png\")\n",
        "    plt.show()\n",
        "\n",
        "def phi_of_theta_with_labels():\n",
        "    theta_line = np.linspace(0, 2*np.pi, 720, endpoint=False)\n",
        "    xy_line = np.stack([np.cos(theta_line), np.sin(theta_line)], axis=-1).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        phi_line = model.enc(torch.from_numpy(xy_line).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "    phi_line -= np.mean(phi_line)\n",
        "    plt.figure(figsize=(6.4,4.2))\n",
        "    plt.plot(theta_line, phi_line, color='0.3')\n",
        "    for tag, th in ICS.items():\n",
        "        with torch.no_grad():\n",
        "            phi_tag = model.enc(torch.from_numpy(np.array([[np.cos(th), np.sin(th)]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "        phi_tag -= np.mean(phi_line)\n",
        "        plt.scatter([th],[phi_tag], s=50, color=TAG_TO_COLOR[tag])\n",
        "        plt.text(th+0.05, phi_tag+0.05, tag, fontsize=11, weight='bold', color=TAG_TO_COLOR[tag])\n",
        "    plt.xlabel(\"θ (radians)\"); plt.ylabel(\"φ(θ)\")\n",
        "    plt.title(\"Learned encoding  φ(θ) (AE pretrain → anneal)\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_phi_of_theta.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_latent_vector_field_with_labels():\n",
        "    theta_line = np.linspace(0, 2*np.pi, 720, endpoint=False)\n",
        "    xy_line = np.stack([np.cos(theta_line), np.sin(theta_line)], axis=-1).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        phi_line = model.enc(torch.from_numpy(xy_line).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "    phi_line = phi_line - np.mean(phi_line)\n",
        "    phi_grid = np.linspace(phi_line.min(), phi_line.max(), 500, dtype=np.float32)\n",
        "    with torch.no_grad():\n",
        "        h_vals = model.h(torch.from_numpy(phi_grid).float().unsqueeze(1).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "    plt.figure(figsize=(6.4,4.2))\n",
        "    plt.plot(phi_grid, h_vals, linewidth=2, color='0.3')\n",
        "    for tag, th in ICS.items():\n",
        "        with torch.no_grad():\n",
        "            phi_tag = model.enc(torch.from_numpy(np.array([[np.cos(th), np.sin(th)]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "            h_tag   = model.h(torch.from_numpy(np.array([[phi_tag]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "        phi_tag -= np.mean(phi_line)\n",
        "        plt.scatter([phi_tag],[h_tag], s=55, color=TAG_TO_COLOR[tag])\n",
        "        plt.text(phi_tag+0.05, h_tag+0.05, tag, fontsize=11, weight='bold', color=TAG_TO_COLOR[tag])\n",
        "    plt.axhline(0, linewidth=1, color='0.7')\n",
        "    plt.xlabel(r\"$\\phi$\"); plt.ylabel(r\"$h(\\phi)=\\dot{\\phi}$\")\n",
        "    plt.title(r\"Latent vector field: $\\dot{\\phi} = h(\\phi)$\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_latent_vf.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_decoder_mapping_views():\n",
        "    theta_line = np.linspace(0, 2*np.pi, 720, endpoint=False)\n",
        "    xy_line = np.stack([np.cos(theta_line), np.sin(theta_line)], axis=-1).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        phi_obs = model.enc(torch.from_numpy(xy_line).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "    phi_obs = phi_obs - np.mean(phi_obs)\n",
        "    phi_grid = np.linspace(phi_obs.min(), phi_obs.max(), 600, dtype=np.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x_dec = model.dec(torch.from_numpy(phi_grid).float().reshape(-1,1).to(DEVICE)).cpu().numpy()\n",
        "    theta_hat = np.arctan2(x_dec[:,1], x_dec[:,0])\n",
        "\n",
        "    # (1) φ vs θ̂(φ)\n",
        "    plt.figure(figsize=(6.4,4.2))\n",
        "    plt.plot(phi_grid, theta_hat, color='0.6')\n",
        "    for tag, th in ICS.items():\n",
        "        with torch.no_grad():\n",
        "            phi_tag = model.enc(torch.from_numpy(np.array([[np.cos(th), np.sin(th)]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "            x_tag  = model.dec(torch.from_numpy(np.array([[phi_tag]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "        phi_tag_c = phi_tag - np.mean(phi_obs)\n",
        "        th_tag = np.arctan2(x_tag[1], x_tag[0])\n",
        "        c = TAG_TO_COLOR[tag]\n",
        "        plt.scatter([phi_tag_c],[th_tag], s=55, color=c)\n",
        "        plt.text(phi_tag_c+0.05, th_tag+0.05, tag, fontsize=11, weight='bold', color=c)\n",
        "    plt.xlabel(r\"$\\phi$\"); plt.ylabel(r\"$\\hat{\\theta}(\\phi)$\")\n",
        "    plt.title(\"Decoder angle mapping  φ → arg D(φ)\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_decoder_angle.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # (2) Decoded curve in R^2\n",
        "    plt.figure(figsize=(6.0,5.6))\n",
        "    td = np.linspace(0, 2*np.pi, 400)\n",
        "    plt.plot(np.cos(td), np.sin(td), alpha=0.25, color='0.7', label=\"unit circle (ref)\")\n",
        "    plt.plot(x_dec[:,0], x_dec[:,1], linewidth=1.4, alpha=0.9, color='0.3', label=\"Decoder(φ-grid)\")\n",
        "\n",
        "    outward = 0.10\n",
        "    line_kw = dict(alpha=0.6, linewidth=0.9)\n",
        "    orig_kw = dict(s=42, zorder=3)\n",
        "    dec_kw  = dict(s=42, zorder=3)\n",
        "\n",
        "    for tag in TAG_LIST:\n",
        "        th = ICS[tag]\n",
        "        x_orig = np.array([np.cos(th), np.sin(th)])\n",
        "        with torch.no_grad():\n",
        "            phi_tag = model.enc(torch.from_numpy(np.array([[x_orig[0], x_orig[1]]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "            x_decoded = model.dec(torch.from_numpy(np.array([[phi_tag]], np.float32)).to(DEVICE)).cpu().numpy().squeeze()\n",
        "\n",
        "        c = TAG_TO_COLOR[tag]\n",
        "        plt.plot([x_orig[0], x_decoded[0]],\n",
        "                 [x_orig[1], x_decoded[1]],\n",
        "                 color=c, **line_kw)\n",
        "        plt.scatter([x_orig[0]],[x_orig[1]], marker='o', color=c, **orig_kw)\n",
        "        plt.scatter([x_decoded[0]],[x_decoded[1]], marker='s', color=c, **dec_kw)\n",
        "\n",
        "        L_out = (1.0 + outward) * x_orig\n",
        "        plt.text(L_out[0], L_out[1], f\"{tag}\",\n",
        "                 fontsize=11, weight='bold', color=c,\n",
        "                 ha='center', va='center',\n",
        "                 bbox=dict(facecolor='white', edgecolor='none', alpha=0.65, pad=0.8))\n",
        "        plt.text(x_decoded[0], x_decoded[1], r\"$%s'$\" % tag,\n",
        "                 fontsize=11, weight='bold', color=c,\n",
        "                 ha='center', va='center',\n",
        "                 bbox=dict(facecolor='white', edgecolor='none', alpha=0.65, pad=0.8))\n",
        "\n",
        "    plt.gca().set_aspect('equal', 'box')\n",
        "    plt.title(\"Decoder image of φ-grid in $\\mathbb{R}^2$\")\n",
        "    plt.xlabel(\"x₁\"); plt.ylabel(\"x₂\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_decoder_R2.png\")\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Radius visualization + printout (FIXED) ----------\n",
        "def plot_decoder_radius_and_print_radii():\n",
        "    \"\"\"\n",
        "    Plot radius ||D(E(x))|| vs θ, overlay A..H, and print\n",
        "    the numeric radii of A'..H' to the console.\n",
        "    Now includes safe label placement.\n",
        "    \"\"\"\n",
        "    theta_line = np.linspace(0, 2*np.pi, 720, endpoint=False)\n",
        "    xy_line = np.stack([np.cos(theta_line), np.sin(theta_line)], axis=-1).astype(np.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        phi_line = model.enc(torch.from_numpy(xy_line).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "\n",
        "    phi_tensor = torch.from_numpy(phi_line).float().reshape(-1,1).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        x_dec = model.dec(phi_tensor).cpu().numpy()\n",
        "\n",
        "    radii = np.linalg.norm(x_dec, axis=1)\n",
        "\n",
        "    # --- Compute safe y-limits before plotting ---\n",
        "    rmin, rmax = radii.min(), radii.max()\n",
        "    pad = 0.05 * (rmax - rmin + 1e-5)\n",
        "    y_lo = rmin - pad\n",
        "    y_hi = rmax + pad\n",
        "\n",
        "    plt.figure(figsize=(7.2,4.2))\n",
        "    plt.plot(theta_line, radii, linewidth=2, color='0.3',\n",
        "             label=r\"$\\|D(E(\\cos\\theta,\\sin\\theta))\\|$\")\n",
        "    plt.axhline(1.0, color='0.6', linestyle='--', label=\"unit radius\")\n",
        "\n",
        "    print(\"\\nDecoded point radii (A'..H'):\")\n",
        "\n",
        "    for tag, th in ICS.items():\n",
        "        x_orig = np.array([np.cos(th), np.sin(th)], dtype=np.float32)\n",
        "        with torch.no_grad():\n",
        "            phi_tag = model.enc(torch.from_numpy(x_orig).unsqueeze(0).to(DEVICE)).cpu().numpy().squeeze()\n",
        "            x_decoded = model.dec(\n",
        "                torch.from_numpy(np.array([[phi_tag]], np.float32)).to(DEVICE)\n",
        "            ).cpu().numpy().squeeze()\n",
        "\n",
        "        r = float(np.linalg.norm(x_decoded))\n",
        "        c = TAG_TO_COLOR[tag]\n",
        "        plt.scatter([th], [r], color=c, s=55)\n",
        "\n",
        "        # Safe label placement *inside* the axes\n",
        "        # Shift upward or downward depending on where the radius sits.\n",
        "        text_offset = 0.015\n",
        "        r_text = r + text_offset*(y_hi - y_lo)\n",
        "        if r_text > y_hi - 0.02:       # If too high, shift downward\n",
        "            r_text = r - text_offset*(y_hi - y_lo)\n",
        "\n",
        "        plt.text(th+0.04, r_text, rf\"{tag}'\", fontsize=10, color=c)\n",
        "\n",
        "        print(f\"  {tag}': radius = {r:.6f}\")\n",
        "\n",
        "    plt.ylim([y_lo, y_hi])\n",
        "    plt.xlabel(\"θ (radians)\")\n",
        "    plt.ylabel(r\"$\\|D(E(\\cos\\theta,\\sin\\theta))\\|$\")\n",
        "    plt.title(\"Decoder radius across θ\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_decoder_radius.png\")\n",
        "    plt.show()\n",
        "\n",
        "def simulate_theta(theta0, steps=220, dt=DT):\n",
        "    th = float(theta0); out = []\n",
        "    for _ in range(steps):\n",
        "        out.append(th); th = th + dt * theta_dot(th)\n",
        "    return np.array(out, dtype=np.float32)\n",
        "\n",
        "def rollout_latent_from_x0(x0, steps=220, dt=DT):\n",
        "    with torch.no_grad():\n",
        "        phi = model.enc(torch.from_numpy(x0.astype(np.float32)).to(DEVICE).unsqueeze(0))\n",
        "    phis = []\n",
        "    for _ in range(steps):\n",
        "        phis.append(phi.cpu().numpy().reshape(()))\n",
        "        with torch.no_grad():\n",
        "            phi = rk4_step(phi, model.h, dt)\n",
        "    phis = np.array(phis, dtype=np.float32)\n",
        "    with torch.no_grad():\n",
        "        xh = model.dec(torch.from_numpy(phis).to(DEVICE).reshape(-1,1)).cpu().numpy()\n",
        "    theta_roll = np.arctan2(xh[:,1], xh[:,0])\n",
        "    return phis, theta_roll\n",
        "\n",
        "def plot_theta_timeseries_subfigs(labels_to_theta, steps=220, dt=DT):\n",
        "    keys = list(labels_to_theta.keys())\n",
        "    thetas0 = [labels_to_theta[k] for k in keys]\n",
        "    fig, axes = plt.subplots(len(thetas0), 1, figsize=(7.5, 2.25*len(thetas0)), sharex=True)\n",
        "    if len(thetas0) == 1: axes = [axes]\n",
        "    for ax, tag, th0 in zip(axes, keys, thetas0):\n",
        "        theta_true = simulate_theta(th0, steps=steps, dt=dt)\n",
        "        x_true = theta_to_xy(theta_true)\n",
        "        with torch.no_grad():\n",
        "            xhat_direct = model.dec(model.enc(torch.from_numpy(x_true).to(DEVICE))).cpu().numpy()\n",
        "        theta_dec = np.arctan2(xhat_direct[:,1], xhat_direct[:,0])\n",
        "        _, theta_roll = rollout_latent_from_x0(x_true[0], steps=steps, dt=dt)\n",
        "\n",
        "        y_true = wrap_angle_numpy(theta_true)\n",
        "        y_dec  = wrap_angle_numpy(theta_dec)\n",
        "        y_roll = wrap_angle_numpy(theta_roll)\n",
        "\n",
        "        t = np.arange(steps)*dt\n",
        "        c = TAG_TO_COLOR[tag]\n",
        "        ax.plot(t, y_true, label=\"θ true (sim)\", color=c)\n",
        "        ax.plot(t, y_dec,  \"--\", label=\"θ decoded D(E(x))\", color=c, alpha=0.85)\n",
        "        ax.plot(t, y_roll, \":\", label=\"θ rollout (RK4)\", color=c, alpha=0.85)\n",
        "        ax.set_ylim([-np.pi, np.pi])\n",
        "        ax.set_yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\n",
        "        ax.set_yticklabels([r\"$-\\pi$\", r\"$-\\pi/2$\", \"0\", r\"$\\pi/2$\", r\"$\\pi$\"])\n",
        "        ax.set_ylabel(r\"θ(t) mod $2\\pi$\")\n",
        "        ax.set_title(f\"{tag}: θ₀ = {th0:.2f} rad\")\n",
        "    axes[-1].set_xlabel(\"time\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_timeseries_AH.png\")\n",
        "    plt.show()\n",
        "\n",
        "# --- θ-domain vector field: helpers + plots ---\n",
        "def _phi_theta_line():\n",
        "    theta_line = np.linspace(0, 2*np.pi, 720, endpoint=False).astype(np.float32)\n",
        "    xy_line = np.stack([np.cos(theta_line), np.sin(theta_line)], axis=-1).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        phi_line = model.enc(torch.from_numpy(xy_line).to(DEVICE)).cpu().numpy().reshape(-1)\n",
        "    phi_line = phi_line - np.mean(phi_line)\n",
        "    return theta_line, phi_line\n",
        "\n",
        "def _pulled_back(theta_line, phi_line, eps=1e-4):\n",
        "    phi_tensor = torch.from_numpy(phi_line.astype(np.float32)).reshape(-1,1).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        h_vals = model.h(phi_tensor).cpu().numpy().reshape(-1)\n",
        "    dtheta = theta_line[1] - theta_line[0]\n",
        "    dphi_dtheta = np.zeros_like(phi_line)\n",
        "    dphi_dtheta[1:-1] = (phi_line[2:] - phi_line[:-2])/(2*dtheta)\n",
        "    dphi_dtheta[0]    = (phi_line[1] - phi_line[-1])/(2*dtheta)\n",
        "    dphi_dtheta[-1]   = (phi_line[0] - phi_line[-2])/(2*dtheta)\n",
        "    theta_dot_hat = h_vals / np.clip(np.abs(dphi_dtheta), eps, None)\n",
        "    return theta_dot_hat\n",
        "\n",
        "def plot_theta_domain_vector_field_comparison():\n",
        "    theta_line, phi_line = _phi_theta_line()\n",
        "    theta_dot_true = np.sin(2.0*theta_line)\n",
        "    theta_dot_hat  = _pulled_back(theta_line, phi_line)\n",
        "\n",
        "    plt.figure(figsize=(7.2,4.2))\n",
        "    plt.plot(theta_line, theta_dot_true, label=r\"true $\\dot{\\theta}(\\theta)=\\sin(2\\theta)$\", color='0.25')\n",
        "    plt.plot(theta_line, theta_dot_hat,  \"--\", label=r\"pulled-back $\\hat{\\dot{\\theta}}(\\theta)$\", color='0.55')\n",
        "    for tag, th in ICS.items():\n",
        "        k = int((th % (2*np.pi)) / (2*np.pi) * len(theta_line))\n",
        "        c = TAG_TO_COLOR[tag]\n",
        "        plt.scatter([th],[theta_dot_true[k]], s=55, color=c, alpha=0.9)\n",
        "        plt.text(th+0.05, theta_dot_true[k]+0.05, tag, fontsize=10, color=c)\n",
        "    plt.xlabel(\"θ (radians)\"); plt.ylabel(\"θ̇(θ)\")\n",
        "    plt.title(\"θ-domain vector field: true vs pulled-back (superimposed)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_thetaVF_superimposed.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_theta_domain_vector_field_true_only():\n",
        "    theta_line, _ = _phi_theta_line()\n",
        "    theta_dot_true = np.sin(2.0*theta_line)\n",
        "    plt.figure(figsize=(7.2,4.2))\n",
        "    plt.plot(theta_line, theta_dot_true, color='C0', linewidth=2)\n",
        "    plt.xlabel(\"θ (radians)\"); plt.ylabel(\"θ̇(θ)\")\n",
        "    plt.title(\"True θ-domain vector field (auto-scaled)\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_thetaVF_true.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_theta_domain_vector_field_pulled_only():\n",
        "    theta_line, phi_line = _phi_theta_line()\n",
        "    theta_dot_hat  = _pulled_back(theta_line, phi_line)\n",
        "    plt.figure(figsize=(7.2,4.2))\n",
        "    plt.plot(theta_line, theta_dot_hat, color='C1', linewidth=2)\n",
        "    plt.xlabel(\"θ (radians)\"); plt.ylabel(r\"$\\hat{\\dot{\\theta}}(\\theta)$\")\n",
        "    plt.title(\"Pulled-back θ-domain vector field (auto-scaled)\")\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_thetaVF_pulled.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Combined with y-lims [-2.2,2.2], saved under the old \"zoom\" name\n",
        "def plot_theta_domain_vector_field_combined_limited():\n",
        "    theta_line, phi_line = _phi_theta_line()\n",
        "    theta_dot_true = np.sin(2.0*theta_line)\n",
        "    theta_dot_hat  = _pulled_back(theta_line, phi_line)\n",
        "\n",
        "    plt.figure(figsize=(7.2,4.2))\n",
        "    plt.plot(theta_line, theta_dot_true, label=\"true θ̇(θ)\", color='C0', linewidth=1.8)\n",
        "    plt.plot(theta_line, theta_dot_hat,  \"--\", label=\"pulled-back θ̇̂(θ)\", color='C1', linewidth=1.8)\n",
        "    plt.ylim([-2.2, 2.2])\n",
        "    plt.xlabel(\"θ (radians)\"); plt.ylabel(\"θ̇(θ)\")\n",
        "    plt.title(\"θ-domain vector field (combined, limited to [-2.2, 2.2])\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    savefig(\"fig_thetaVF_pulled_zoom.png\")\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Generate & save all figures\n",
        "# ----------------------------\n",
        "quiver_circle_with_labels()\n",
        "phi_of_theta_with_labels()\n",
        "plot_latent_vector_field_with_labels()\n",
        "plot_decoder_mapping_views()\n",
        "plot_decoder_radius_and_print_radii()   # radius figure + console printout\n",
        "\n",
        "plot_theta_domain_vector_field_comparison()\n",
        "plot_theta_domain_vector_field_true_only()\n",
        "plot_theta_domain_vector_field_pulled_only()\n",
        "plot_theta_domain_vector_field_combined_limited()\n",
        "\n",
        "plot_theta_timeseries_subfigs(ICS, steps=220, dt=DT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kwaqs4zll22",
        "outputId": "a57fde4e-3ac0-4226-8c83-058485127833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:373: SyntaxWarning: invalid escape sequence '\\m'\n",
            "<>:373: SyntaxWarning: invalid escape sequence '\\m'\n",
            "/tmp/ipython-input-3951123987.py:373: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  plt.title(\"Decoder image of φ-grid in $\\mathbb{R}^2$\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Phase 1 | epochs=500 | W_REC=15.0 W_CONJ=0.0 W_LAT1=0.0 | lr=0.002 ===\n",
            "  ep    1 | rec 5.553e-01 | conj 0.000e+00 | lat1 0.000e+00 | total 8.330e+00\n",
            "  ep  100 | rec 2.378e-02 | conj 0.000e+00 | lat1 0.000e+00 | total 3.567e-01\n",
            "  ep  200 | rec 7.890e-03 | conj 0.000e+00 | lat1 0.000e+00 | total 1.184e-01\n"
          ]
        }
      ]
    }
  ]
}